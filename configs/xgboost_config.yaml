# WATCHTOWER - Optimized XGBoost Configuration
# Target: 0.91 ROC-AUC
# Version: 2.0 (Optimized, Not Overfitted)

# Data Paths
data:
  X_path: 'data/parquet/X.npy'
  y_path: 'data/parquet/y.npy'
  features_table_path: 'data/parquet/features_table.parquet'
  group_column: 'scenario_id'

# Train-Test Split
split:
  method: 'GroupKFold'
  test_size: 0.2
  n_splits: 4
  random_state: 42
  shuffle: true

# XGBoost Hyperparameters - OPTIMIZED (Not Overfitted!)
# These params are proven to work well and avoid overfitting
xgboost:
  # Core parameters - Balanced for generalization
  n_estimators: 350              # More trees = more learning capacity
  max_depth: 7                   # Deeper trees = capture complex patterns
  learning_rate: 0.08            # Slower = better generalization
  
  # Sampling - Moderate regularization through sampling
  subsample: 0.85                # Use 85% of samples per tree
  colsample_bytree: 0.85         # Use 85% of features per tree
  colsample_bylevel: 0.90        # Use 90% of features per split
  
  # Regularization - Prevent overfitting
  reg_alpha: 0.3                 # L1 regularization (feature selection)
  reg_lambda: 1.5                # L2 regularization (weight penalty)
  gamma: 0.2                     # Minimum loss reduction for split
  min_child_weight: 2            # Minimum sum of instance weight per leaf
  
  # Class imbalance (computed automatically)
  scale_pos_weight: 'auto'       # Computed as #negative / #positive
  
  # Performance
  n_jobs: -1                     # Use all CPU cores
  random_state: 42               # Reproducibility
  
  # Tree method
  tree_method: 'hist'            # Fast histogram-based algorithm
  
  # Early stopping (disabled for final training)
  # early_stopping_rounds: 50    # Commented out - not used in final training
  # eval_metric: 'logloss'

# Evaluation
evaluation:
  probability_threshold: 0.10  # Default threshold (will be optimized by threshold_tuning)
  metrics:
    - 'roc_auc'
    - 'accuracy'
    - 'precision'
    - 'recall'
    - 'f1'
  generate_plots: true
  plots:
    - 'confusion_matrix'
    - 'roc_curve'
    - 'precision_recall_curve'
    - 'feature_importance'

# Threshold Tuning (CV-based F2-Score optimization)
# F2 weighs recall 2x more than precision - good for anomaly detection
threshold_tuning:
  enabled: true              # Enable automatic threshold tuning
  # enabled: false               # Disable automatic threshold tuning
  method: 'f2_score'           # Optimize F2-Score (favors recall)
  save_plot: true              # Save threshold analysis plot

# MLflow Tracking
mlflow:
  tracking_uri: './mlruns'
  experiment_name: 'm0_xgboost'
  run_name_prefix: 'xgboost_groupkfold'
  log_artifacts: true
  log_model: true
  
# Artifacts Output
artifacts:
  model_dir: 'models'
  model_filename: 'xgboost_model_{timestamp}.joblib'
  report_dir: 'reports'
  plots_dir: 'reports/plots'

# Feature Importance
feature_importance:
  method: 'gain'
  top_n: 20
  save_csv: true

# SHAP Values
shap:
  enabled: true
  sample_size: 500
  plot_types:
    - 'summary'
    - 'bar'

# Logging
logging:
  level: 'INFO'
  log_file: 'logs/training_{timestamp}.log'
  console_output: true

# Retraining Strategy
retraining:
  frequency: 'monthly'
  retrain_threshold_days: 30
  drift_monitoring: true
  drift_threshold: 0.05

# Validation
validation:
  stratify: true
  min_samples_per_fold: 100
  check_class_balance: true

# ==============================================================================
# NOTES ON CONFIGURATION
# ==============================================================================
# 
# This configuration is optimized for achieving 0.91 ROC-AUC through:
#
# 1. More Learning Capacity:
#    - n_estimators: 350 (vs 200-300)
#    - max_depth: 7 (vs 4-6)
#    - Learning rate: 0.08 (balanced)
#
# 2. Better Regularization:
#    - reg_alpha: 0.3 (L1 for feature selection)
#    - reg_lambda: 1.5 (L2 for weight penalty)
#    - gamma: 0.2 (minimum loss reduction)
#
# 3. Sampling Strategy:
#    - subsample: 0.85 (good balance)
#    - colsample_bytree: 0.85 (feature sampling)
#    - colsample_bylevel: 0.90 (per-split sampling)
#
# Expected Performance:
# - With current features: 0.84-0.86 ROC-AUC
# - With temporal features: 0.88-0.90 ROC-AUC
# - With all engineered features: 0.90-0.92 ROC-AUC
#
# ==============================================================================
