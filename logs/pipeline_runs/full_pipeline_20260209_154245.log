
================================================================================
WATCHTOWER ETL PIPELINE
Data Curation and Cleaning
================================================================================
Start time: 2026-02-09 15:42:51
Data path: data/raw/sutd
================================================================================
================================================================================
WATCHTOWER ETL CONFIGURATION
================================================================================

Column Mappings: 29 mappings
Required Columns: 6
Numeric Columns: 12
Clipping Ranges: 9

Output Directory: data/parquet
Clean Data File: clean_data.parquet
================================================================================
â„¹ï¸  
================================================================================
â„¹ï¸  WATCHTOWER ETL PIPELINE - DATA CURATION AND CLEANING
â„¹ï¸  ================================================================================
â„¹ï¸  Start time: 2026-02-09 15:42:51
â„¹ï¸  
================================================================================
â„¹ï¸  STEP 1: EXTRACT - Loading Raw CSV Files
â„¹ï¸  ================================================================================
â„¹ï¸  Found 4 CSV file(s)
â„¹ï¸    âœ“ Loaded Lvl4_AllRRUOn_Anomaly_label.csv: 2,327 rows
â„¹ï¸    âœ“ Loaded Lvl5_AllRRUOn_Anomaly_label.csv: 2,031 rows
â„¹ï¸    âœ“ Loaded Lvl6_1RRUOn_Anomaly_label.csv: 2,156 rows
â„¹ï¸    âœ“ Loaded Lvl6_AllRRUOn_Anomaly_label.csv: 2,222 rows
â„¹ï¸  
âœ… Loaded 8,736 total rows from 4 files
â„¹ï¸  
================================================================================
â„¹ï¸  STEP 2A: TRANSFORM - Standardize Column Names
â„¹ï¸  ================================================================================
â„¹ï¸  Renamed 16 columns:
â„¹ï¸    â€¢ Time â†’ time_s
â„¹ï¸    â€¢ NR-ARFCN â†’ nr_arfcn
â„¹ï¸    â€¢ PCI â†’ pci
â„¹ï¸    â€¢ C-RNTI â†’ c_rnti
â„¹ï¸    â€¢ RSRP â†’ rsrp_dbm
â„¹ï¸    â€¢ RSRQ â†’ rsrq_db
â„¹ï¸    â€¢ SINR â†’ sinr_db
â„¹ï¸    â€¢ PDSCH_MCS â†’ mcs_dl
â„¹ï¸    â€¢ PUSCH_MCS â†’ mcs_ul
â„¹ï¸    â€¢ PDSCH PRBs â†’ prb_dl
â„¹ï¸    ... and 6 more
â„¹ï¸  
âœ… Column standardization complete
â„¹ï¸  
================================================================================
â„¹ï¸  STEP 2B: TRANSFORM - Type Coercion
â„¹ï¸  ================================================================================
â„¹ï¸    ğŸ“… Detected datetime format in time_s column, parsing...
â„¹ï¸    âœ“ Converted datetime strings to relative seconds (per scenario)
â„¹ï¸  âœ… Coerced 11 numeric columns
â„¹ï¸  
================================================================================
â„¹ï¸  STEP 2C: TRANSFORM - Add Absolute Timestamp
â„¹ï¸  ================================================================================
â„¹ï¸  Time range: 1497.62 seconds
â„¹ï¸  Number of records: 8,736
â„¹ï¸  Average sampling rate: 5.83 Hz
â„¹ï¸  Timestamp range: 1700000000000000000 to 1700001497624084480
â„¹ï¸  
âœ… Absolute timestamps added (ts_ns)
â„¹ï¸  
================================================================================
â„¹ï¸  STEP 2D: TRANSFORM - Range Clipping (Sanity Checks)
â„¹ï¸  ================================================================================
â„¹ï¸    âœ“ rsrp_dbm: All values within [-156, -31]
â„¹ï¸    âœ‚ï¸  rsrq_db: Clipped 85 values to [-20, 3]
â„¹ï¸        (85 below, 0 above) - Empirical radio quality envelope
â„¹ï¸    âœ‚ï¸  sinr_db: Clipped 2,131 values to [-10, 30]
â„¹ï¸        (36 below, 2,095 above) - Indoor testbed limits
â„¹ï¸    âœ“ mcs_dl: All values within [0, 28]
â„¹ï¸    âœ“ mcs_ul: All values within [0, 28]
â„¹ï¸    âœ“ prb_dl: All values within [0, 273]
â„¹ï¸    âœ“ prb_ul: All values within [0, 273]
â„¹ï¸    âœ‚ï¸  app_dl_mbps: Clipped 4,938 values to [0, 100000000]
â„¹ï¸        (0 below, 4,938 above) - Avoid corrupt iPerf3 logs (testbed limit)
â„¹ï¸  
âœ… Clipped 7,154 values across 3 columns
â„¹ï¸  
================================================================================
â„¹ï¸  STEP 2E: TRANSFORM - Handle Nulls and Duplicates
â„¹ï¸  ================================================================================
â„¹ï¸  
TIER 1: Dropping rows with nulls in critical columns
â„¹ï¸    ğŸ—‘ï¸  Dropped 10 rows (0.11%) with critical nulls:
â„¹ï¸        sinr_db: 10 nulls
â„¹ï¸  
TIER 2: Imputing nulls in operational columns
â„¹ï¸    âœ“ mcs_dl: Filled 99 nulls using mode
â„¹ï¸        Reason: MCS is categorical, use most common value
â„¹ï¸    âœ“ mcs_ul: Filled 98 nulls using mode
â„¹ï¸        Reason: MCS is categorical, use most common value
â„¹ï¸    âœ“ prb_dl: Filled 99 nulls using median
â„¹ï¸        Reason: PRB usage is continuous, median is robust
â„¹ï¸    âœ“ prb_ul: Filled 98 nulls using median
â„¹ï¸        Reason: PRB usage is continuous, median is robust
â„¹ï¸  
Removing duplicate rows
â„¹ï¸    âœ“ No duplicate rows found
â„¹ï¸  
âœ… Null handling complete:
â„¹ï¸     Rows: 8,736 â†’ 8,726 (10 dropped)
â„¹ï¸     Critical nulls: 10 rows dropped
â„¹ï¸     Operational nulls: 394 values imputed
â„¹ï¸     Duplicates: 0 rows dropped
â„¹ï¸  
================================================================================
â„¹ï¸  STEP 2F: TRANSFORM - Finalize Output
â„¹ï¸  ================================================================================
â„¹ï¸    âœ“ Sorted by scenario_id and ts_ns
â„¹ï¸    âœ“ Selected 17 columns
â„¹ï¸    âœ“ Final shape: 8,726 rows Ã— 17 columns
â„¹ï¸  
================================================================================
â„¹ï¸  STEP 3: VALIDATE - GX Validation on Cleaned Data
â„¹ï¸  ================================================================================
================================================================================
WATCHTOWER DATA VALIDATION
================================================================================
âœ… Loaded 8,726 samples from temp_clean.csv (csv)
ğŸ“‹ Detected ETL-CLEANED data format (standardized column names)

ğŸ” Validating Schema...
  âœ“ time_s
  âœ“ rsrp_dbm
  âœ“ rsrq_db
  âœ“ sinr_db
  âœ“ mcs_dl
  âœ“ app_dl_mbps
  âœ“ lab_anom

ğŸ” Validating Null Values...
  âœ“ time_s: No nulls
  âœ“ rsrp_dbm: No nulls
  âœ“ rsrq_db: No nulls
  âœ“ sinr_db: No nulls
  âœ“ lab_anom: No nulls
  âœ“ mcs_dl: 0.00% nulls (â‰¤5.0% allowed)
  âœ“ mcs_ul: 0.00% nulls (â‰¤5.0% allowed)
  âœ“ app_dl_mbps: 0.00% nulls (â‰¤2.0% allowed)

ğŸ” Validating Numeric Ranges (3GPP Standards)...
  âœ“ rsrp_dbm: [-156, -31] (95%)
  âœ“ rsrq_db: [-20, 3] (95%)
  âœ“ sinr_db: [-10, 30] (95%)
  âœ“ mcs_dl: [0, 28] (strict)
  âœ“ mcs_ul: [0, 28] (strict)
  âœ“ prb_dl: [0, 273] (strict)
  âœ“ prb_ul: [0, 273] (strict)
  âœ“ app_dl_mbps: [0, 100000000] (95%)

ğŸ” Validating Categorical Values...
  âœ“ lab_anom: [0, 1]
  âœ“ lab_inf: [0, 1]
  âœ“ lab_1rr: [0, 1]

ğŸ” Validating Anomaly Signatures...
  âœ“ SINR separation: 14.6 dB (â‰¥10 dB)
  âœ“ Anomaly SINR < 15 dB: 73.4%
  âœ“ Throughput drop: 39.6%

ğŸ” Validating Data Quality...
  âœ“ Samples: 8,726 (â‰¥5,000)
  âœ“ Duplicates: 0.00% (â‰¤1.0%)
  âœ“ Anomaly rate: 45.6% (20.0-60.0%)
  âœ“ Overall nulls: 0.00% (â‰¤5.0%)

ğŸ” Validating Scenario-Specific Rules...
  âœ“ Lvl4_AllRRUOn: 2,324 samples, 35.6% anomalies
  âœ“ Lvl5_AllRRUOn: 2,025 samples, 58.5% anomalies
  âœ“ Lvl6_1RRUOn: 2,155 samples, 39.9% anomalies
  âœ“ Lvl6_AllRRUOn: 2,222 samples, 50.0% anomalies

================================================================================
VALIDATION SUMMARY: 41/41 checks passed
================================================================================
âœ… All validation checks passed!

ğŸ“„ Validation report saved: reports/validation/validation_report_20260209_154251.json
âœ… âœ… All validation checks passed!
â„¹ï¸  
================================================================================
â„¹ï¸  STEP 4: LOAD - Export to Parquet
â„¹ï¸  ================================================================================
â„¹ï¸    âœ“ Saved to: data/parquet/clean_data.parquet
â„¹ï¸    âœ“ File size: 0.17 MB
â„¹ï¸    âœ“ Compression: snappy
â„¹ï¸    âœ“ ETL statistics saved: reports/etl_report.json
â„¹ï¸    âœ“ Clipping statistics saved: reports/clipping_statistics.json
âœ… âœ… Logged to MLflow
â„¹ï¸  
================================================================================
âœ… ETL PIPELINE COMPLETE
â„¹ï¸  ================================================================================
â„¹ï¸  Duration: 0.82 seconds
â„¹ï¸  Input:  8,736 rows
â„¹ï¸  Output: 8,726 rows
â„¹ï¸  Dropped: 10 rows
â„¹ï¸  Clipped: 7,154 values
â„¹ï¸  Saved to: data/parquet/clean_data.parquet
â„¹ï¸  ================================================================================

================================================================================
PIPELINE SUMMARY
================================================================================
âœ… Status: SUCCESS
âœ… Input rows: 8,736
âœ… Output rows: 8,726
âœ… Rows dropped: 10
âœ… Values clipped: 7,154
âœ… Duration: 0.82 seconds

ğŸ“„ Output file: data/parquet/clean_data.parquet
ğŸ“Š File size: 0.17 MB

âœ… Validation: PASSED (41/41 checks)

ğŸ“Š MLflow: Logged to experiment 'watchtower_etl'
   View UI: mlflow ui

================================================================================
Next steps:
  1. Review cleaned data: data/parquet/clean_data.parquet
  2. Check ETL report: reports/etl_report.json
  3. Proceed to windowing: python run_windowing.py
================================================================================


================================================================================
WATCHTOWER WINDOWING PIPELINE
5-Second Window Aggregation + Derived Features
================================================================================
Start time: 2026-02-09 15:42:55
Input path: data/parquet/clean_data.parquet
================================================================================
================================================================================
WATCHTOWER WINDOWING CONFIGURATION
================================================================================

Window Parameters:
  Window size: 5 seconds
  Sample rate: 2 Hz
  Samples per window: 10
  Min samples threshold: 7.0

Aggregations:
  rsrp_dbm: mean, std
  rsrq_db: mean, std
  sinr_db: mean, std, min, max
  prb_dl: mean
  prb_ul: mean
  app_dl_mbps: mean, std
  mcs_dl: mode
  mcs_ul: mode
  pci: mode

Derived Features:
  Delta features: 5
  Ratio features: 3

Output:
  Windows file: data/parquet/windows.parquet
  Expected columns: 28
================================================================================
â„¹ï¸  
================================================================================
â„¹ï¸  WATCHTOWER WINDOWING PIPELINE
â„¹ï¸  5-Second Windows + Derived Features
â„¹ï¸  ================================================================================
â„¹ï¸  Start time: 2026-02-09 15:42:55
â„¹ï¸  
================================================================================
â„¹ï¸  STEP 1: Load Clean Data
â„¹ï¸  ================================================================================
â„¹ï¸  Loaded: 8,726 rows Ã— 17 columns
â„¹ï¸  Time range: 1700000000000000000 to 1700001497624084480
â„¹ï¸  Scenarios: 4
â„¹ï¸  
================================================================================
â„¹ï¸  STEP 2: Create Time Windows
â„¹ï¸  ================================================================================
â„¹ï¸  Window size: 5 seconds
â„¹ï¸  Expected samples per window: 10
â„¹ï¸    âœ“ Lvl4_AllRRUOn_Anomaly_label: 232 windows created
â„¹ï¸    âœ“ Lvl5_AllRRUOn_Anomaly_label: 202 windows created
â„¹ï¸    âœ“ Lvl6_1RRUOn_Anomaly_label: 215 windows created
â„¹ï¸    âœ“ Lvl6_AllRRUOn_Anomaly_label: 222 windows created
â„¹ï¸  
âœ… Created 871 windows from 8,726 samples
â„¹ï¸     Window creation rate: 99.8%
â„¹ï¸  
================================================================================
â„¹ï¸  STEP 3: Add Derived Features
â„¹ï¸  ================================================================================
â„¹ï¸  
Adding delta features (temporal changes):
â„¹ï¸    âœ“ d_rsrp_mean: Change in rsrp_mean
â„¹ï¸    âœ“ d_rsrq_mean: Change in rsrq_mean
â„¹ï¸    âœ“ d_sinr_mean: Change in sinr_mean
â„¹ï¸    âœ“ d_sinr_std: Change in sinr_std
â„¹ï¸    âœ“ d_app_dl_mean: Change in app_dl_mean
â„¹ï¸  
Adding ratio features (signal quality indices):
â„¹ï¸    âœ“ rsrp_rsrq_ratio: Signal strength to quality ratio
â„¹ï¸    âœ“ sinr_range: SINR volatility within window
â„¹ï¸    âœ“ throughput_per_prb: Throughput efficiency (Mbps per PRB)
â„¹ï¸  
âœ… Added 5 delta features + 3 ratio features
â„¹ï¸  
================================================================================
â„¹ï¸  STEP 4: Validation and Quality Checks
â„¹ï¸  ================================================================================
â„¹ï¸  âœ“ Window count: 871 windows
â„¹ï¸  âœ“ Gap ratio: 0.00% (avg), 0.00% (max)
â„¹ï¸  âœ“ Anomaly rate: 50.40%
â„¹ï¸  
Feature Statistics:
â„¹ï¸    SINR mean: 17.05 dB
â„¹ï¸    SINR std: 1.61 dB
â„¹ï¸    Throughput mean: 78288472.70 Mbps
â„¹ï¸  
âœ… Validation complete
â„¹ï¸  
================================================================================
â„¹ï¸  STEP 5: Export Windows to Parquet
â„¹ï¸  ================================================================================
â„¹ï¸    âœ“ CSV preview saved to: data/parquet/windows.csv
â„¹ï¸    âœ“ Saved to: data/parquet/windows.parquet
â„¹ï¸    âœ“ File size: 0.10 MB
â„¹ï¸    âœ“ Rows: 871
â„¹ï¸    âœ“ Columns: 28
â„¹ï¸    âœ“ Metrics saved: reports/windowing_metrics.json
â„¹ï¸  
Creating visualizations:
â„¹ï¸    âœ“ Preview plot: reports/plots/windowing_preview.png
â„¹ï¸    âœ“ Distribution plot: reports/plots/windowing_distribution.png
âœ… âœ… Logged to MLflow
â„¹ï¸  
================================================================================
âœ… WINDOWING PIPELINE COMPLETE
â„¹ï¸  ================================================================================
â„¹ï¸  Duration: 3.20 seconds
â„¹ï¸  Input:  8,726 samples
â„¹ï¸  Output: 871 windows
â„¹ï¸  Anomaly rate: 50.4%
â„¹ï¸  Saved to: data/parquet/windows.parquet
â„¹ï¸  ================================================================================

================================================================================
PIPELINE SUMMARY
================================================================================
âœ… Status: SUCCESS
âœ… Input samples: 8,726
âœ… Output windows: 871
âœ… Window size: 5 seconds
âœ… Samples per window: 10
âœ… Gap ratio (avg): 0.00%
âœ… Anomaly rate: 50.4%
âœ… Duration: 3.20 seconds

ğŸ“„ Output file: data/parquet/windows.parquet
ğŸ“Š File size: 0.10 MB
ğŸ“Š Columns: 28

ğŸ“ˆ Visualizations:
   - SINR time series: reports/plots/windowing_preview.png
   - Feature distributions: reports/plots/windowing_distribution.png

ğŸ“Š MLflow: Logged to experiment 'watchtower_windowing'
   View UI: mlflow ui

================================================================================
Next steps:
  1. Review windowed data: data/parquet/windows.parquet
  2. Check metrics: reports/windowing_metrics.json
  3. View plots: reports/plots/windowing_preview.png
  4. Proceed to model training!
================================================================================


================================================================================
WATCHTOWER FEATURE TABLE BUILDER
Build features_table.parquet from windows.parquet
================================================================================
Start time: 2026-02-09 15:43:00
Input path: data/parquet/windows.parquet
================================================================================
================================================================================
WATCHTOWER FEATURE TABLE CONFIGURATION
================================================================================

Input: data/parquet/windows.parquet
Output: data/parquet/features_table.parquet

Features:
  Existing numeric: 22
  New derived: 7
  Total numeric: 29
  Categorical: 2
  Total features: 31

New Derived Features:
  â€¢ prb_util_ratio: Downlink PRB utilization ratio
  â€¢ hour_sin: Hour of day (sine component)
  â€¢ hour_cos: Hour of day (cosine component)
  â€¢ sinr_cv: SINR coefficient of variation
  â€¢ throughput_efficiency: Throughput per unit SINR
  â€¢ is_single_rru: Binary: 1=single RRU (Lvl6_1RRUOn), 0=all RRUs
  â€¢ scenario_level: Numeric scenario level (4, 5, or 6)

Output Columns: 33
================================================================================
â„¹ï¸  
================================================================================
â„¹ï¸  WATCHTOWER FEATURE TABLE BUILDER
â„¹ï¸  ================================================================================
â„¹ï¸  Start time: 2026-02-09 15:43:00
â„¹ï¸  
================================================================================
â„¹ï¸  STEP 1: Load Windows
â„¹ï¸  ================================================================================
â„¹ï¸  Loaded: 871 windows
â„¹ï¸  Columns: 28
â„¹ï¸  Scenarios: 4
â„¹ï¸  
================================================================================
â„¹ï¸  STEP 2: Sort Data (Required for Derivatives!)
â„¹ï¸  ================================================================================
â„¹ï¸  Sorted by: ['scenario_id', 'ts_start_ns']
â„¹ï¸  âœ“ Order is now correct for derivative calculations
â„¹ï¸  
================================================================================
â„¹ï¸  STEP 3: Create Derived Features
â„¹ï¸  ================================================================================
â„¹ï¸  âœ“ Created: prb_util_ratio
â„¹ï¸      Downlink PRB utilization ratio
â„¹ï¸  âœ“ Created: hour_sin
â„¹ï¸      Hour of day (sine component)
â„¹ï¸  âœ“ Created: hour_cos
â„¹ï¸      Hour of day (cosine component)
â„¹ï¸  âœ“ Created: sinr_cv
â„¹ï¸      SINR coefficient of variation
â„¹ï¸  âœ“ Created: throughput_efficiency
â„¹ï¸      Throughput per unit SINR
â„¹ï¸  âœ“ Created: is_single_rru
â„¹ï¸      Binary: 1=single RRU (Lvl6_1RRUOn), 0=all RRUs
â„¹ï¸  âœ“ Created: scenario_level
â„¹ï¸      Numeric scenario level (4, 5, or 6)
â„¹ï¸  
âœ… Created 7 new derived features
â„¹ï¸  
================================================================================
â„¹ï¸  STEP 4: Select Features (Fixed Order)
â„¹ï¸  ================================================================================
â„¹ï¸  Selected: 33/33 columns
â„¹ï¸    Metadata: 1
â„¹ï¸    Numeric: 29
â„¹ï¸    Categorical: 2
â„¹ï¸    Target: 1
â„¹ï¸  
================================================================================
â„¹ï¸  STEP 5: Validate Data Quality
â„¹ï¸  ================================================================================
â„¹ï¸  âœ“ Window count: 871
â„¹ï¸  âœ“ No missing values
â„¹ï¸  
Feature Statistics:
â„¹ï¸    SINR mean: 17.05 dB
â„¹ï¸    SINR range: 5.10 dB
â„¹ï¸    Throughput: 78288472.70 Mbps
â„¹ï¸  
Target Distribution:
â„¹ï¸    Normal (0): 432 (49.6%)
â„¹ï¸    Anomaly (1): 439 (50.4%)
â„¹ï¸  
âœ… Validation complete
â„¹ï¸  
================================================================================
â„¹ï¸  STEP 6: Save Feature Table
â„¹ï¸  ================================================================================
â„¹ï¸  âœ“ Saved to: data/parquet/features_table.parquet
â„¹ï¸    Rows: 871
â„¹ï¸    Columns: 33
â„¹ï¸    Size: 0.12 MB
â„¹ï¸  âœ“ Saved statistics: reports/feature_table_stats.json
â„¹ï¸  
================================================================================
âœ… FEATURE TABLE BUILD COMPLETE
â„¹ï¸  ================================================================================
â„¹ï¸  Duration: 0.02 seconds
â„¹ï¸  Input: 871 windows
â„¹ï¸  Output: 871 rows Ã— 33 columns
â„¹ï¸  Features: 31
â„¹ï¸  File: data/parquet/features_table.parquet
â„¹ï¸  ================================================================================

================================================================================
PIPELINE SUMMARY
================================================================================
âœ… Status: SUCCESS
âœ… Input windows: 871
âœ… Output rows: 871
âœ… Output columns: 33
âœ… Features created: 31
âœ… New derived features: 7
âœ… Duration: 0.02 seconds

ğŸ“„ Output file:
   data/parquet/features_table.parquet
   Size: 0.12 MB
   Shape: (871, 33)

ğŸ“Š Statistics saved to:
   reports/feature_table_stats.json

================================================================================
Next steps:
  1. Review feature table: data/parquet/features_table.parquet
  2. Check statistics: reports/feature_table_stats.json
  3. Proceed to scaling & encoding (next instruction)
================================================================================

Loading configuration from: configs/preprocessing_config.yaml
Loaded config from configs/preprocessing_config.yaml
Preprocessing pipeline initialized
Starting preprocessing pipeline...

================================================================================
WATCHTOWER PREPROCESSING PIPELINE
================================================================================
Loading features from: data/parquet/features_table.parquet
âœ… Loaded 871 samples Ã— 33 columns
âœ… All required columns present
================================================================================
FITTING STANDARD SCALER
================================================================================
Shape: (871, 29) (29 features)
âœ… Fitted StandardScaler

Sample scaling (first 5 features):
  rsrp_mean            â†’ mean=-100.594, std=  13.669
  rsrp_std             â†’ mean=   1.975, std=   1.473
  rsrq_mean            â†’ mean= -11.332, std=   1.814
  rsrq_std             â†’ mean=   0.344, std=   0.618
  sinr_mean            â†’ mean=  17.047, std=  11.379
================================================================================
FITTING ONE-HOT ENCODER
================================================================================
Shape: (871, 2) (2 features)
âœ… Fitted OneHotEncoder (handle_unknown='ignore')

Categories:
  pci_mode        â†’  2 unique values
  scenario_id     â†’  4 unique values

Total one-hot features: 6
================================================================================
TRANSFORMING DATA
================================================================================
âœ… Scaled numeric: (871, 29)
âœ… Encoded categorical: (871, 6)
âœ… Combined X: (871, 35)
âœ… Target y: (871,)
   Class 0/1: [432 439], Anomaly rate: 50.4%
âœ… Metadata: (871,)
================================================================================
SAVING ARTIFACTS
================================================================================
âœ… artifacts/scaler.joblib
âœ… artifacts/onehot.joblib
âœ… artifacts/feature_order.json (35 features)
================================================================================
SAVING CONFIGURATION
================================================================================
âœ… configs/feature_config.yaml
================================================================================
EXPORTING DESIGN MATRICES
================================================================================
âœ… data/parquet/X.npy
   Shape: (871, 35), dtype: float32, size: 0.12 MB
âœ… data/parquet/y.npy
   Shape: (871,), dtype: int8, size: 0.87 KB
âœ… data/parquet/meta_ts.npy
   Shape: (871,), dtype: int64, size: 6.97 KB
âœ… data/parquet/preprocessing_features.csv
   Shape: (871, 37), size: 0.31 MB
================================================================================
PREPROCESSING COMPLETE âœ…
================================================================================

X: 871 samples Ã— 35 features
y: 871 samples

âœ… Ready for XGBoost training!
================================================================================

ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ 
WATCHTOWER PREPROCESSING PIPELINE
Fit Transformers and Export Preprocessed Data
ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ 


================================================================================
âœ… PREPROCESSING PIPELINE COMPLETE!
================================================================================

Outputs:
  ğŸ“Š X.npy: 871 samples Ã— 35 features
  ğŸ¯ y.npy: 871 labels
  ğŸ”§ scaler.joblib: StandardScaler
  ğŸ”§ onehot.joblib: OneHotEncoder
  ğŸ“‹ feature_order.json: 35 features

================================================================================
NEXT STEPS:
================================================================================
1. Load X.npy and y.npy
2. Perform train-test split (GroupKFold)
3. Train XGBoost model
4. Evaluate with SHAP values
================================================================================

Loading configuration from: configs/xgboost_config.yaml
Loaded config from configs/xgboost_config.yaml
XGBoost Trainer initialized
Starting XGBoost training pipeline...

ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ 
WATCHTOWER - XGBOOST TRAINING PIPELINE
ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ 

================================================================================
LOADING DATA
================================================================================
âœ… Loaded X: (871, 35)
âœ… Loaded y: (871,)
âœ… Loaded groups: (871,)
   Unique scenarios: ['Lvl4_AllRRUOn_Anomaly_label' 'Lvl5_AllRRUOn_Anomaly_label'
 'Lvl6_1RRUOn_Anomaly_label' 'Lvl6_AllRRUOn_Anomaly_label']
   Scenario counts: {'Lvl4_AllRRUOn_Anomaly_label': 232, 'Lvl5_AllRRUOn_Anomaly_label': 202, 'Lvl6_1RRUOn_Anomaly_label': 215, 'Lvl6_AllRRUOn_Anomaly_label': 222}

Class distribution:
   Class 0: 432 samples (49.6%)
   Class 1: 439 samples (50.4%)

================================================================================
GROUPKFOLD CROSS-VALIDATION
================================================================================

================================================================================
FOLD 1/4
================================================================================
Train scenarios: ['Lvl5_AllRRUOn_Anomaly_label' 'Lvl6_1RRUOn_Anomaly_label'
 'Lvl6_AllRRUOn_Anomaly_label']
Test scenarios: ['Lvl4_AllRRUOn_Anomaly_label']
Train size: 639 samples
Test size: 232 samples

Class imbalance:
   Negative samples: 309
   Positive samples: 330
   scale_pos_weight: 0.936

XGBoost configuration:
   n_estimators: 350
   max_depth: 7
   learning_rate: 0.08
   subsample: 0.85
   colsample_bytree: 0.85
   colsample_bylevel: 0.9
   reg_alpha: 0.3
   reg_lambda: 1.5
   gamma: 0.2
   min_child_weight: 2
   scale_pos_weight: 0.9363636363636364
   n_jobs: -1
   random_state: 42
   tree_method: hist

Training fold 1...

Fold 1 Results:
   ROC-AUC:   0.8768
   PR-AUC:    0.8532
   Brier:     0.4408
   Accuracy:  0.4871
   Precision: 0.4781
   Recall:    1.0000
   F1-Score:  0.6469

================================================================================
FOLD 2/4
================================================================================
Train scenarios: ['Lvl4_AllRRUOn_Anomaly_label' 'Lvl5_AllRRUOn_Anomaly_label'
 'Lvl6_1RRUOn_Anomaly_label']
Test scenarios: ['Lvl6_AllRRUOn_Anomaly_label']
Train size: 649 samples
Test size: 222 samples

Class imbalance:
   Negative samples: 321
   Positive samples: 328
   scale_pos_weight: 0.979

XGBoost configuration:
   n_estimators: 350
   max_depth: 7
   learning_rate: 0.08
   subsample: 0.85
   colsample_bytree: 0.85
   colsample_bylevel: 0.9
   reg_alpha: 0.3
   reg_lambda: 1.5
   gamma: 0.2
   min_child_weight: 2
   scale_pos_weight: 0.9786585365853658
   n_jobs: -1
   random_state: 42
   tree_method: hist

Training fold 2...

Fold 2 Results:
   ROC-AUC:   0.9169
   PR-AUC:    0.9453
   Brier:     0.1538
   Accuracy:  0.8378
   Precision: 1.0000
   Recall:    0.6757
   F1-Score:  0.8065

================================================================================
FOLD 3/4
================================================================================
Train scenarios: ['Lvl4_AllRRUOn_Anomaly_label' 'Lvl5_AllRRUOn_Anomaly_label'
 'Lvl6_AllRRUOn_Anomaly_label']
Test scenarios: ['Lvl6_1RRUOn_Anomaly_label']
Train size: 656 samples
Test size: 215 samples

Class imbalance:
   Negative samples: 304
   Positive samples: 352
   scale_pos_weight: 0.864

XGBoost configuration:
   n_estimators: 350
   max_depth: 7
   learning_rate: 0.08
   subsample: 0.85
   colsample_bytree: 0.85
   colsample_bylevel: 0.9
   reg_alpha: 0.3
   reg_lambda: 1.5
   gamma: 0.2
   min_child_weight: 2
   scale_pos_weight: 0.8636363636363636
   n_jobs: -1
   random_state: 42
   tree_method: hist

Training fold 3...

Fold 3 Results:
   ROC-AUC:   0.9776
   PR-AUC:    0.9723
   Brier:     0.1781
   Accuracy:  0.7116
   Precision: 0.5850
   Recall:    0.9885
   F1-Score:  0.7350

================================================================================
FOLD 4/4
================================================================================
Train scenarios: ['Lvl4_AllRRUOn_Anomaly_label' 'Lvl6_1RRUOn_Anomaly_label'
 'Lvl6_AllRRUOn_Anomaly_label']
Test scenarios: ['Lvl5_AllRRUOn_Anomaly_label']
Train size: 669 samples
Test size: 202 samples

Class imbalance:
   Negative samples: 362
   Positive samples: 307
   scale_pos_weight: 1.179

XGBoost configuration:
   n_estimators: 350
   max_depth: 7
   learning_rate: 0.08
   subsample: 0.85
   colsample_bytree: 0.85
   colsample_bylevel: 0.9
   reg_alpha: 0.3
   reg_lambda: 1.5
   gamma: 0.2
   min_child_weight: 2
   scale_pos_weight: 1.1791530944625408
   n_jobs: -1
   random_state: 42
   tree_method: hist

Training fold 4...

Fold 4 Results:
   ROC-AUC:   0.9602
   PR-AUC:    0.9819
   Brier:     0.1368
   Accuracy:  0.8663
   Precision: 1.0000
   Recall:    0.7955
   F1-Score:  0.8861

================================================================================
CROSS-VALIDATION SUMMARY
================================================================================

Mean ROC-AUC:   0.9329 Â± 0.0392 (4/4 valid folds)
Mean PR-AUC:    0.9382 Â± 0.0508
Mean Brier:     0.2274 Â± 0.1433 (lower is better)
Mean Accuracy:  0.7257 Â± 0.1727
Mean Precision: 0.7658 Â± 0.2740
Mean Recall:    0.8649 Â± 0.1572
Mean F1-Score:  0.7686 Â± 0.1019

================================================================================
TRAINING FINAL MODEL ON ALL DATA
================================================================================

Class imbalance:
   Negative samples: 432
   Positive samples: 439
   scale_pos_weight: 0.984

XGBoost configuration (final model):
   n_estimators: 350
   max_depth: 7
   learning_rate: 0.08
   subsample: 0.85
   colsample_bytree: 0.85
   colsample_bylevel: 0.9
   reg_alpha: 0.3
   reg_lambda: 1.5
   gamma: 0.2
   min_child_weight: 2
   scale_pos_weight: 0.9840546697038725
   n_jobs: -1
   random_state: 42
   tree_method: hist

Training on 871 samples...
âœ… Final model trained successfully
âœ… Model saved: models/xgboost_model_20260209_154303.joblib
ğŸ§¹ Cleaned up 6 old plot file(s)
âœ… Saved confusion matrix: reports/plots/confusion_matrix_20260209_154303.png
âœ… Saved ROC curve: reports/plots/roc_curve_20260209_154303.png
âœ… Saved feature importance: reports/plots/feature_importance_20260209_154303.png
âœ… Saved calibration curve: reports/plots/calibration_curve_20260209_154303.png
âœ… Saved probability distribution: reports/plots/probability_distribution_20260209_154303.png

================================================================================
PROBABILITY DISTRIBUTION ANALYSIS
================================================================================

Normal Samples (Class 0): n=432
  Mean probability:   0.371
  Median probability: 0.040
  Std probability:    0.430
  Range:              [0.000, 0.999]

Anomaly Samples (Class 1): n=439
  Mean probability:   0.828
  Median probability: 0.995
  Std probability:    0.337
  Range:              [0.001, 1.000]

Class Separation Analysis:
  Normal samples in overlap zone (0.3-0.7): 35 (8.1%)
  Anomaly samples with high confidence (>0.7): 357 (81.3%)
  Anomaly samples with low probability (<0.3): 64 (14.6%)

  Mean probability difference: 0.457
  Separation Quality: GOOD - Reasonable separation
================================================================================
Pooled 871 samples from 4 folds

============================================================
CV THRESHOLD TUNING WITH F2-SCORE
============================================================

Optimal Threshold: 0.1000
F2-Score:          0.8312
Precision:         0.6610
Recall:            0.8884
F1-Score:          0.7580
Accuracy:          0.7141

ğŸ“Š FALSE ALARM ANALYSIS:
  FPR (statistical):    46.3%
  FAR (operational):    165.3 false alarms/hour
  Total Alerts:         487.7 alerts/hour
  Time Between FA:      0.4 minutes

Confusion Matrix:
  TP: 390 | FP: 200
  FN: 49 | TN: 232

Interpretation:
  Catches 88.8% of anomalies
  66.1% of alerts are real anomalies

ğŸš¨ Operational Status: âŒ HIGH - Alarm fatigue risk
============================================================

======================================================================
FALSE ALARM ANALYSIS AT DIFFERENT THRESHOLDS
======================================================================

FPR = False Positive Rate = FP / (FP + TN) [Statistical]
FAR = False Alarms per Hour [Operational - what operators experience]

Threshold 0.10: Recall= 88.8%, Precision= 66.1%, FPR= 46.3%, FAR= 165.3/hour
Threshold 0.15: Recall= 87.5%, Precision= 66.6%, FPR= 44.7%, FAR= 159.5/hour
Threshold 0.20: Recall= 86.8%, Precision= 67.1%, FPR= 43.3%, FAR= 154.6/hour
Threshold 0.25: Recall= 86.3%, Precision= 67.3%, FPR= 42.6%, FAR= 152.1/hour
Threshold 0.30: Recall= 85.4%, Precision= 67.6%, FPR= 41.7%, FAR= 148.8/hour
Threshold 0.35: Recall= 85.0%, Precision= 67.9%, FPR= 40.7%, FAR= 145.5/hour
Threshold 0.40: Recall= 84.7%, Precision= 68.4%, FPR= 39.8%, FAR= 142.2/hour
Threshold 0.50: Recall= 83.6%, Precision= 68.6%, FPR= 38.9%, FAR= 138.9/hour

----------------------------------------------------------------------
OPERATIONAL TRADE-OFF ANALYSIS:
----------------------------------------------------------------------

----------------------------------------------------------------------
RECOMMENDATION:
----------------------------------------------------------------------
  âš ï¸ No threshold achieves <= 30 FA/hour. Consider improving model or features.
======================================================================

============================================================
THRESHOLD VALIDATION PER FOLD
============================================================
Fold 1: F2=0.8171, Precision=0.4719, Recall=1.0000
Fold 2: F2=0.8019, Precision=0.9884, Recall=0.7658
Fold 3: F2=0.8415, Precision=0.5276, Recall=0.9885
Fold 4: F2=0.8621, Precision=1.0000, Recall=0.8333

Summary (threshold=0.1000):
  Mean F2:       0.8306 Â± 0.0266
  Mean Precision: 0.7470 Â± 0.2864
  Mean Recall:    0.8969 Â± 0.1158
  Stability:      GOOD (stable)
============================================================
âœ… Saved threshold analysis plot: reports/plots/threshold_analysis.png
âœ… Saved optimal threshold config: configs/optimal_threshold_20260209_154303.json

================================================================================
LOGGING TO MLFLOW
================================================================================
2026/02/09 15:43:06 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.
Exception ignored in: <function Image.__del__ at 0x7914e06691c0>
Traceback (most recent call last):
  File "/home/himanshu/miniconda3/lib/python3.13/tkinter/__init__.py", line 4258, in __del__
    self.tk.call('image', 'delete', self.name)
RuntimeError: main thread is not in main loop
âœ… Logged to MLflow experiment: m0_xgboost
   Run name: xgboost_groupkfold_20260209_154303

================================================================================
âœ… TRAINING COMPLETE!
================================================================================

Model saved: models/xgboost_model_20260209_154303.joblib
Mean CV ROC-AUC: 0.9329
Mean CV PR-AUC:  0.9382
Mean CV Brier:   0.2274 (lower is better)
Mean CV Accuracy: 0.7257

â­ OPTIMAL THRESHOLD (F2): 0.1000
   At this threshold:
   - Recall: 0.8884 (catches 88.8% of anomalies)
   - Precision: 0.6610
   - FPR: 0.4630 (46.3% false positive rate)
   - FAR: 165.3 false alarms/hour
   - F2-Score: 0.8312

================================================================================

ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ 
WATCHTOWER - XGBOOST TRAINING PIPELINE
M0: XGBoost Anomaly Detection Model
ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯ 


================================================================================
âœ… TRAINING PIPELINE COMPLETE!
================================================================================

Outputs:
  ğŸ¯ Model: models/xgboost_model_*.joblib
  ğŸ“Š Plots: reports/plots/
  ğŸ“ˆ MLflow: mlruns/

================================================================================
NEXT STEPS:
================================================================================
1. View training results:
   mlflow ui --backend-store-uri file://mlruns
   Then open: http://localhost:5000

2. Inspect model performance:
   - Check reports/plots/ for visualizations
   - Review confusion matrix and ROC curve

3. Deploy model:
   - Use saved model in models/ directory
   - Implement FastAPI inference endpoint
================================================================================

